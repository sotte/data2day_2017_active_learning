#+REVEAL_ROOT: reveal.js
#+REVEAL_THEME: serif
#+REVEAL_TRANS: slide
#+OPTIONS: reveal_title_slide:nil
#+OPTIONS: toc:nil
#+OPTIONS: num:nil
#+OPTIONS: reveal_history:t
* Gamification von Suche mit Bandits und Swipes

oder: Wie man mit Small Data arbeitet

/Stefan Otte/

https://goo.gl/tPrBVN

[[./img/qr.png]]
* 
:PROPERTIES: 
:reveal_background: img/dr_strangelove.jpg
:reveal_background_size: 50%
:END:

#+BEGIN_NOTES
1. Filler: zu schnell
2. Guter Film: urkomisch
3. Titel Dr Strangelove inspiriert den 'spirituellen Titel' des Talks
#+END_NOTES
* Active Learning or: How I Learned to Stop Worrying and Love Small Data
#+BEGIN_NOTES
- show of hands
- Message: Werbeveranstaltung fuer AL
#+END_NOTES
* 
/Stefan Otte/

https://github.com/sotte

** 
:PROPERTIES: 
:reveal_background: img/pr2.jpg
:reveal_background_size: 80%
:END:
** 
:PROPERTIES: 
:reveal_background: img/um.png
:reveal_background_size: 400px
:END:
#+BEGIN_NOTES
Big Data

from idea to cable

- Data Engineering
- Ops
- Data Science
- Data Thinking - Beratungsspalte

from idea to cable

#+END_NOTES
* Where are we going?
#+BEGIN_NOTES
- Talks bei "Data" Konferenzen sind etwas komisch
- sehr diverses publikum
  - Engineers, Big Data Zoo: Big Data Engineers, ML, Mathe und Physiker PhD,
  - Data Scientist -> Daten Hausmeister
  - Marketing, Sales, Manager und C-Level
 
Dieser Talks ist auch komisch
- High Level / Novice
- Theory -> wichtig
- Formel -> PhD, griechische Buchstaben
- Beispiel fuer die Formel
- Konkretes Fallbeispiel einer App
- Big Data Engineers: Seitenhieb -> small data

Ziel:
- active learning
#+END_NOTES
* The Task
#+BEGIN_NOTES
- Entwickle "diese App" fuer Porsche Austria
- fun, engaging, gamified, personalized
- Suchen von Autos genutzt wird
- Geschmack des Users erlernt
- Problem: keine Daten ueber Nutzer vorhanden -> AL

Besseres Interface
#+END_NOTES
* 
:PROPERTIES: 
:reveal_background: img/cars.png
:reveal_background_size: 100%
:END:
* 
:PROPERTIES: 
:reveal_background: img/cars2.png
:reveal_background_size: 100%
:END:
* 
:PROPERTIES: 
:reveal_background: img/cars3.png
:reveal_background_size: 100%
:END:
* 
:PROPERTIES: 
:reveal_background: img/cars4.png
:reveal_background_size: 100%
:END:
* 
:PROPERTIES: 
:reveal_background: img/cars5.png
:reveal_background_size: 100%
:END:
* 
[[./img/cinder.png]]
#+BEGIN_NOTES
Fallbeispiel - koennte erzaehlen wir alles umgesetzt haben, lessons learned, etc.

Aber, hier ist hier mehr.
Theory -> AL
#+END_NOTES
* /"Nothing Is Quite So Practical as a Good Theory"/ 
-- Kurt Lewin
#+BEGIN_NOTES
German-American Psychologist
pioneers of social, organizational, and applied psychology
Founder of social psychology
#+END_NOTES
* Active Learning
#+BEGIN_NOTES
Unterdefinierte Welt
#+END_NOTES
** 
/"The key idea behind *active learning* is that a machine learning algorithm can achieve *greater accuracy* with *fewer training labels* if it is allowed to *choose the data* from which it learns./
** 
/An active learner may *pose queries*, usually in the form of unlabeled data instances to be labeled by an oracle (e.g., a human annotator)./
** 
/Active learning is well-motivated in many modern machine learning problems, where unlabeled data may be abundant or easily obtained, but *labels are difficult, time-consuming, or expensive to obtain*."/

-- Burr Settles, Active Learning Literature Survey

#+BEGIN_NOTES
- greater accuracy
- fewer training labels
- pose queries
- when labels are expensive
#+END_NOTES
** 
:PROPERTIES: 
:reveal_background: img/al.png
:reveal_background_trans: slide
:reveal_background_size: 50%
:END:

#+BEGIN_NOTES
- Buch 
- Survey als PDF

~70 Seiten
#+END_NOTES
** 
:PROPERTIES: 
:reveal_background: img/burr_settles.jpg
:reveal_background_trans: slide
:END:
#+BEGIN_NOTES
ML department von CMU?
G8 demo
#+END_NOTES
** 
greater accuracy with fewer training labels

#+ATTR_REVEAL: :frag (roll-in)
*\rightarrow "good data^{TM}"*
 
actively query for data

#+ATTR_REVEAL: :frag (roll-in)
*\rightarrow sequential decision making*

#+BEGIN_NOTES
Der Kern von Active Learning - zwei Punkte

Gute Daten, nicht big data

Signal to Noise Verhaeltnis

Andere Problemdefinition -> sequential decision making
#+END_NOTES
* ${\huge \textbf{X} \rightarrow} \begin{bmatrix} cat\\ dog\\ \vdots\\ cat \end{bmatrix}$
* ${\huge \textbf{X} \rightarrow} \begin{bmatrix} ?\\ ?\\ \vdots\\ ? \end{bmatrix}$
#+BEGIN_NOTES
AL ist anders.

- nicht unsupervised
- semi-supervised Limbo
- Aber: Moeglichkeit Fragen zu stellen
#+END_NOTES
* What is *Interesting*?
* 
:PROPERTIES: 
:reveal_background: img/al_scenarios.svg.p0.svg
:reveal_background_trans: slide
:reveal_background_size: 50%
:END:
* 
:PROPERTIES: 
:reveal_background: img/al_scenarios.svg.p1.svg
:reveal_background_trans: slide
:reveal_background_size: 50%
:END:
* 
:PROPERTIES: 
:reveal_background: img/al_scenarios.svg.p2.svg
:reveal_background_trans: slide
:reveal_background_size: 50%
:END:
* 
:PROPERTIES: 
:reveal_background: img/al_scenarios.svg.p3.svg
:reveal_background_trans: slide
:reveal_background_size: 50%
:END:
* 
:PROPERTIES: 
:reveal_background: img/al_scenarios.svg.p4.svg
:reveal_background_trans: slide
:reveal_background_size: 50%
:END:
* 
:PROPERTIES: 
:reveal_background: img/al_scenarios.svg.p5.svg
:reveal_background_trans: slide
:reveal_background_size: 50%
:END:
* 
:PROPERTIES: 
:reveal_background: img/al_scenarios.svg.p6.svg
:reveal_background_trans: slide
:reveal_background_size: 50%
:END:
* 
:PROPERTIES: 
:reveal_background: img/al_scenarios.svg.p7.svg
:reveal_background_trans: slide
:reveal_background_size: 50%
:END:
* 
:PROPERTIES: 
:reveal_background: img/al_scenarios.svg.p8.svg
:reveal_background_trans: slide
:reveal_background_size: 50%
:END:
* 
:PROPERTIES: 
:reveal_background: img/al_scenarios.svg.p9.svg
:reveal_background_trans: slide
:reveal_background_size: 50%
:END:
#+BEGIN_NOTES
klaeglicher Versuch Varianz eines GP in Grafikprogramm zu zeichnen.
#+END_NOTES
* What is *Interesting*?
#+ATTR_REVEAL: :frag appear
- uncertainty
  - least confident
  - margin
  - entropy
- query-by-committee
- expected model change (decision theory)
- expected error reduction
- expected variance reduction
- ...
#+BEGIN_NOTES
- Unterschiedliche Methoden
- Problem-spezifisch
- Existierende Klassifikator weiterverwenden
- Runtime Anforderungen - Oelbohrungen vs unsere App
#+END_NOTES
* 
:PROPERTIES: 
:reveal_background: img/tcr.png
:reveal_background_size: 100%
:END:

#+BEGIN_NOTES
- active learning to make a robot explore and learn a room
- learn properties of the world (movable and in what way)
- expected information gain
- robot created the data, not the human
- Selbstlernende Systeme
#+END_NOTES
* Gamification of Search
#+BEGIN_NOTES
Das war der Theory-Teil

Mit dem Wissen gucken wir uns das Problem noch mal an.
#+END_NOTES
* 
:PROPERTIES: 
:reveal_background: img/cars.png
:reveal_background_size: 100%
:END:
#+BEGIN_NOTES
Swipen ist gut, benutzen wir.

Suche ist nicht Schwarz und Weiss.
#+END_NOTES
* 
:PROPERTIES: 
:reveal_background: img/cars10.png
:reveal_background_size: 100%
:END:
* 
:PROPERTIES: 
:reveal_background: img/cars11.png
:reveal_background_size: 100%
:END:
* 
:PROPERTIES: 
:reveal_background: img/cars12.png
:reveal_background_size: 100%
:END:
* 
:PROPERTIES: 
:reveal_background: img/cars13.png
:reveal_background_size: 100%
:END:
#+BEGIN_NOTES
- Swiping nutzen
- Unsicherheit nutzen
- AL nutzen
#+END_NOTES
* 
:PROPERTIES: 
:reveal_background: img/vegas.jpg
:reveal_background_size: 100%
:END:
#+BEGIN_NOTES
- Slot machines
- Reihe von Einarmigen-Banditen -> multi-armed
- Spiele bandits, ziehe an den Armen, und maximiere Gewinn
#+END_NOTES
** Multi-Armed Bandits
Problem statement
#+ATTR_REVEAL: :frag (roll-in)
1. Find a multi-armed bandit
2. Play arms using bandit theory
3. Profit $$$
** Problem statement
- given a bandit with $n$ arms
- each arm $i \in {1,\dots,n}$ returns reward 
$$y \sim P(y; \theta_i)$$

#+ATTR_REVEAL: :frag (roll-in)
*Goal*: Find a policy that 
$$\max \sum_{t=1}^T y_t$$

* UCB
#+ATTR_REVEAL: :frag roll-in
past performance + exploration bonus
#+BEGIN_NOTES
- Upper confident bound
- "Optimism in the face of uncertainty"
- "Optimismus im Angesicht der Unsicherheit"
- Greedy
- Not optimal, but bounded
- Exploration vs Exploitation
- Many variations of UCB
#+END_NOTES
** UCB1
#+ATTR_REVEAL: :frag roll-in
Play each arm once

#+ATTR_REVEAL: :frag roll-in
Then play arm that $$\Large \arg\max_i \; \bar\mu_i + \sqrt{\frac{2\ln n}{n_i}}$$
#+ATTR_REVEAL: :frag roll-in
  - $\bar\mu_i$: mean reward of arm $i$
  - $n$: total rounds played
  - $n_i$: rounds arm $i$ was played

* Demo
* Where are we?
#+BEGIN_NOTES
- active learning
- bandits
- UCB family
- UCB1 example

- app with swiping
- using bandits
#+END_NOTES
* One Bandit per Feature
#+ATTR_REVEAL: :frag (roll-in)
- brand bandit
  - arms: Porsche, VW, ...
- car body bandit
  - arms: SUV, coupe, ...
- segment bandit
  - arms: sports car, economy, ...

#+BEGIN_NOTES
Porsche und VW sind auspraegungeng des Features 'Brand'

Wenn man swiped,
zieht man einen Arm an jedem multi-armed Bandit.
D.h. man zieht an drei Armen.

each bandit creates a *ranking* for the given feature
#+END_NOTES

* Ranking with Elasticsearch
#+BEGIN_NOTES
- ES made for creating rankings
- output of bandits is input of elasticsearch query
#+END_NOTES
[[./img/es_ranking.png]]
[[./img/es.png]]
* Practical Remarks
#+BEGIN_NOTES
Ende meiner Werbeveranstaltung fuer AL
#+END_NOTES
** Popularity Bias
:PROPERTIES: 
:reveal_background: img/bias.png
:reveal_background_size: 100%
:END:
** 
:PROPERTIES: 
:reveal_background: img/segmentation.png
:reveal_background_size: 120%
:END:
#+BEGIN_NOTES
- Sparse PCA to find set of sparse components that can optimally reconstruct the data
- Then clustering
#+END_NOTES
** Implementation
#+ATTR_REVEAL: :frag (roll-in)
- Python
- sklearn
- Flask REST API
- Elasticsearch
* Conclusion
*Active Learning*

Or: How I Learned to Stop Worrying and Love Small Data

* Related Topics
- Sequential Decision Making
- Experimental Design
- (Bayesian) Reinforcement Learning
- Global Optimizaiton
- Optimal solution exists: planning in *belief space*, but is infeasible
- Tuning hyperparams with [[https://github.com/zygmuntz/hyperband][Hyperband]]

* References
- [[http://burrsettles.com/pub/settles.activelearning.pdf][Active Learning Literature Survey]]
- [[http://homes.dsi.unimi.it/~cesabian/Pubblicazioni/ml-02.pdf][Finite-time Analysis of the Multiarmed Bandit Problem - Auer et al]]
- [[https://ipvs.informatik.uni-stuttgart.de/mlr/marc/teaching/14-BanditsOptimizationActiveLearningBayesianRL.pdf][Bandits, Global Optimization, Active Learning, and Bayesian RL -- understanding the common ground - Toussaint]] [[https://www.youtube.com/watch?v=5rev-zVx1Ps][video]]

* Thanks!
*Questions?*

/Stefan Otte/

https://goo.gl/tPrBVN

[[./img/qr.png]]
